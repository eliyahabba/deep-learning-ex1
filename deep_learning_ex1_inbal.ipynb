{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_learning_ex1_inbal.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "osjDIOahJiyD"
      },
      "source": [
        "!pip install ConfigFactory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLkrtyqlJW-r"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ifGzonSW-0R"
      },
      "source": [
        "### Create train-test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI0NmbfAQZFr",
        "outputId": "358619a8-1ab3-457c-f058-62c8fdc15720"
      },
      "source": [
        "with open ('neg_A0201.txt', 'r') as f:\n",
        "    neg_text = f.read().splitlines() \n",
        "    neg_label = [0] * len(neg_text)\n",
        "    print(f\"number of neg labels: {len(neg_label)}\")\n",
        "\n",
        "with open ('pos_A0201.txt', 'r') as f:\n",
        "    pos_text = f.read().splitlines() \n",
        "    pos_label = [1] * len(pos_text)\n",
        "    print(f\"number of pos labels: {len(pos_label)}\")\n",
        "\n",
        "\n",
        "data_text = neg_text + pos_text\n",
        "data_label = neg_label + pos_label\n",
        "\n",
        "# print(data_text)\n",
        "# print(data_label)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of neg labels: 24492\n",
            "number of pos labels: 2991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxL1p_8eoAHc"
      },
      "source": [
        "import string\n",
        "\n",
        "def one_hot_encoder(text):\n",
        "    alphabet = string.ascii_uppercase\n",
        "    vector = torch.Tensor([[0 if char != letter else 1 for char in alphabet] for letter in text])\n",
        "    return vector"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdprGYjgf4ef"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_text, data_label, test_size=0.10, random_state=42)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tYFFSCKe991"
      },
      "source": [
        "import torch \n",
        "import string\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class Dataset(Dataset):\n",
        "  def __init__(self, data_text, data_labels):\n",
        "    self.data_text = data_text\n",
        "    self.data_labels = data_labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_text)\n",
        "    \n",
        "  def one_hot_encoder(text):\n",
        "    alphabet = string.ascii_uppercase\n",
        "    encoding = torch.Tensor([[0 if char != letter else 1 for char in alphabet] for letter in text])\n",
        "    return encoding\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        return dict(gene = self.data_text[index],\n",
        "                    encoded_gene = one_hot_encoder(self.data_text[index])\n",
        "                    label = torch.FloatTensot(self.data_labels[index]))\n",
        "  "
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-hxqit1XY7H"
      },
      "source": [
        "### Create data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7JI6mAEf7Pa"
      },
      "source": [
        "BATCH_SIZE = 64"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YC9v_TpXU_1"
      },
      "source": [
        "from torch.utils.data import sampler, WeightedRandomSampler\n",
        "import torch\n",
        "\n",
        "# Oversample minority class\n",
        "class_sample_count = torch.Tensor([len(neg_text), len(pos_text)])\n",
        "weights = 1. / class_sample_count.float()\n",
        "samples_weights = torch.tensor([weight[t] for t in data_label])\n",
        "\n",
        "# checking the code above is correct\n",
        "# target = torch.Tensor(data_label)\n",
        "# class_sample_count = torch.tensor(\n",
        "#     [(target == t).sum() for t in torch.unique(target, sorted=True)])\n",
        "# print(class_sample_count)\n",
        "\n",
        "\n",
        "# check if replacemnent???\n",
        "sampler = WeightedRandomSampler(weights=samples_weights, num_samples=len(samples_weights))\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtA8GeX4XYYj"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# make Dataset\n",
        "train_dataset = Dataset(X_train, y_train)\n",
        "test_dataset = Dataset(X_test, y_test)\n",
        "\n",
        "# maske DataLoader\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, sampler=sampler)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, sampler=sampler)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeIc6cQqI-8X"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdLJatxpX_hc"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7-W1Wg9YCmh"
      },
      "source": [
        "activiation function = ....\n",
        "\n",
        "# Set up a multi-layered perceptron network to accept this data and output the proper prediction \n",
        "# (detect / not detect). Try different architectural changes (e.g., different number of levels, neurons at each level, etc.), \n",
        "#and non-linearities (RelU, sigmoid) and pick the one achieving the highest accuracy on the test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvs_GzZ8JBSL"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square, you can specify with a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = torch.flatten(x, 1)  # flatten all dimensions except the batch dimension\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWCayk0JJFu6"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzKQpPaHRRyM"
      },
      "source": [
        "!pip install -q pyhocon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtALENxbLC2V"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "from pyhocon import ConfigFactory"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2BKMgkgJHfI"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "import ConfigFactory as ConfigFactory\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "\n",
        "from data_iterator import get_train_test_data\n",
        "from models import Net\n",
        "from stats import Stats\n",
        "\n",
        "classes = ['positive', 'negative']\n",
        "\n",
        "\n",
        "def save_test_eval_to_tensorboard(stats, total_loss, correct, total, epoch, class_total, class_correct):\n",
        "    stats.summary_writer.add_scalar('test/loss', total_loss, epoch)\n",
        "    stats.summary_writer.add_scalar('test/acc', 100 * correct / total, epoch)\n",
        "    stats.summary_writer.add_scalar('test/correct', correct, epoch)\n",
        "    w_acc = np.average([100 * class_correct[i] / class_total[i] for i in range((len(classes)))])\n",
        "    stats.summary_writer.add_scalar('test/weight_acc', w_acc, epoch)\n",
        "    print('Test Accuracy of the model: {} % after %{} epochs'.format(100 * correct / total, epoch))\n",
        "    print('weight Accuracy of the model: {} % after %{} epochs'.format(w_acc, epoch))\n",
        "\n",
        "    for i in range(len(classes)):\n",
        "        stats.summary_writer.add_scalar('test/correct_%s' % classes[i], class_correct[i], epoch)\n",
        "        print(class_total[i], i)\n",
        "        stats.summary_writer.add_scalar('test/acc_%s' % classes[i], 100 * class_correct[i] / class_total[i],\n",
        "                                        epoch)\n",
        "\n",
        "\n",
        "def calculate_model_results(test_labels, outputs, total, correct, total_loss, class_total, class_correct):\n",
        "    _, predicted = torch.max(outputs.detach(), 1)\n",
        "    test_labels_tensor = torch.as_tensor(test_labels)\n",
        "\n",
        "    total += test_labels_tensor.size(0)\n",
        "    correct += (predicted == test_labels_tensor).sum().item()\n",
        "    total_loss += criterion(outputs, test_labels_tensor)\n",
        "\n",
        "    c = (predicted == test_labels_tensor).squeeze()\n",
        "    for i in range(len(test_labels_tensor)):\n",
        "        label = test_labels_tensor[i]\n",
        "        class_correct[label] += c[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "\n",
        "def eval_test_data(net, test_loader, stats, epoch):\n",
        "    with torch.no_grad():\n",
        "        correct, total, total_loss = 0, 0, 0\n",
        "        class_correct, class_total = [0] * len(classes), [0] * len(classes)\n",
        "\n",
        "        for test_data in test_loader:\n",
        "            test_inputs, test_labels = test_data\n",
        "            outputs = net(test_inputs)\n",
        "            calculate_model_results(test_labels, outputs, total, correct, total_loss, class_total,\n",
        "                                    class_correct)\n",
        "\n",
        "        # save to tensorboard object\n",
        "        save_test_eval_to_tensorboard(stats, total_loss, correct, total, epoch, class_total, class_correct)\n",
        "\n",
        "\n",
        "def train(model_path, config):\n",
        "    net = Net()\n",
        "\n",
        "    lr = config['learning_rate']\n",
        "    epochs = config['epochs']\n",
        "    batch_size = config['batch_size']\n",
        "\n",
        "    # choose the optimizer\n",
        "    if config['optimizer'] == 'adam':\n",
        "        optimizer = optim.Adam(params=net.parameters(), lr=lr)\n",
        "    else:\n",
        "        optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "    train_loader, test_loader = get_train_test_data(batch_size)\n",
        "    print('train_loader len is {}'.format(len(train_loader.dataset)))\n",
        "    print('test_loader len is {}'.format(len(test_loader.dataset)))\n",
        "\n",
        "    stats_keys = ['loss']\n",
        "    print_step = 1\n",
        "    stats = Stats(stats_keys, log_dir=model_path, print_step=print_step, prefix='train/')\n",
        "    step = 0\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        for data in train_loader:\n",
        "            step += 1\n",
        "            inputs, inputs_labels = data\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs.float())\n",
        "\n",
        "            loss = criterion(outputs, inputs_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics of train\n",
        "            stats.summary_writer.add_scalar('train/loss', loss, step)\n",
        "\n",
        "            net.eval()\n",
        "            if epoch % config['checkpoint_every'] == 0:\n",
        "                net.save(os.path.join(model_path, '%d.ckpt' % epoch))\n",
        "\n",
        "            eval_test_data(net, test_loader, stats, epoch)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('config', help='config args for train model')\n",
        "    parser.add_argument('--config-file', default=os.path.join(os.getcwd(), 'config.conf'))\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    model_path = os.path.join(os.getcwd(), args.config)\n",
        "    config = ConfigFactory.parse_file(args.config_file)[args.config]\n",
        "    if not os.path.exists(model_path):\n",
        "        os.makedirs(model_path)\n",
        "    train(model_path, config)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-epFU4pZJTfO"
      },
      "source": [
        "# Stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P_logzwJUoG"
      },
      "source": [
        "import numpy as np\n",
        "from time import time\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "class Stats(object):\n",
        "    def __init__(self, keys, log_dir=None, print_step=100, prefix=None):\n",
        "        self.keys = keys\n",
        "        self.summary_writer = SummaryWriter(log_dir)\n",
        "        self.print_step = print_step\n",
        "        self.prefix = prefix\n",
        "        self.sums = {k: .0 for k in keys}\n",
        "        self.start_time = time()\n",
        "        self.count = 0\n",
        "\n",
        "    def clear(self):\n",
        "        for key in self.sums:\n",
        "            self.sums[key] = .0\n",
        "        self.start_time = time()\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, *args):\n",
        "        for key, val in zip(self.keys, args):\n",
        "            self.sums[key] += float(val)\n",
        "        self.count += 1\n",
        "\n",
        "    def summarize(self, step):\n",
        "        stats = dict.fromkeys(self.sums)\n",
        "        for key in self.sums:\n",
        "            stats[key] = self.sums[key] / self.count\n",
        "            tag = key if self.prefix is None else self.prefix + key\n",
        "            self.summary_writer.add_scalar(tag, stats[key], step)\n",
        "        time_ms = int(np.round(1e3 * (time() - self.start_time)) / self.count)\n",
        "        return stats, time_ms\n",
        "\n",
        "    def pretty_print(self, step, stats, time_ms):\n",
        "        step_str = ['{:<8}'.format(str(step) + ')')]\n",
        "        stats_str = ['{}: {:<9.4f}'.format(k, stats[k]) for k in self.keys]\n",
        "        time_str = ['{:>10}'.format('(' + str(time_ms) + ' msec)')]\n",
        "        str_out = ' '.join(step_str + stats_str + time_str)\n",
        "        print(str_out)\n",
        "\n",
        "    def __call__(self, step, *args):\n",
        "        self.update(*args)\n",
        "        if (step + 1) % self.print_step == 0:\n",
        "            stats, time_ms = self.summarize(step)\n",
        "            self.clear()\n",
        "            self.pretty_print(step + 1, stats, time_ms)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}