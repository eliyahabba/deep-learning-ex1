base = {
  # model
  model: NeuralNetwork
  batch_size: 32
  epochs: 10

  # learning rate
  learning_rate: 0.001
  learning_rate_decay {
    enabled: true
    decay_steps: 100
    decay_rate: 0.999
    staircase: false
  }
  weight_decay: 0.0001

  # optimizer
  optimizer: adam

  # ours params
  checkpoint_every: 10
}

base_lr_0.01 = {
  # model
  model: NeuralNetwork
  batch_size: 32
  epochs: 10

  # learning rate
  learning_rate: 0.01
  learning_rate_decay {
    enabled: true
    decay_steps: 100
    decay_rate: 0.999
    staircase: false
  }
  weight_decay: 0.0001

  # optimizer
  optimizer: adam

  # ours params
  checkpoint_every: 10
}

